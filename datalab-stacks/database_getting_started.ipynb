{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with your database\n",
    "### Database-coding using SQLAlchemy and another (!!) Jupyter Notebook\n",
    "Start a [Vanilla Jupyterlab](ControlBoard.ipynb#Vanilla-Jupyter-Datascience-Notebook) instance, then **copy** the code snippets below. Don't use this AWK DataLab Controlboard directly ;-).\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "from urllib import parse\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Connect to your database\n",
    "SQLAlchemy let's you use the same syntax and logic for different databases. All you need to change is the connection piece. You'll receive an `Engine`-object from SQLAlchemy (the connection won't be established until you do something with it). [Check here](https://docs.sqlalchemy.org/en/13/core/connections.html) to get started.\n",
    "\n",
    "#### The Passwords will be different for you\n",
    "To get the passwords below, use the initial `helm upgrade --install ...` command. Or (more complex), grab the [passwords from the respective Kubernetes secret](https://kubernetes.io/docs/tasks/configmap-secret/managing-secret-using-kubectl/#decoding-secret), e.g. named `postgresql`.\n",
    "\n",
    "#### PostgreSQL (state of the art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of your database - this database does NOT exist yet (create it below with `create_database()`)\n",
    "database = 'my-new-database'\n",
    "username = 'dbuser'\n",
    "password = 's0ZKgBffaP1hVgumGkuLsbd4'\n",
    "\n",
    "# Connection details according to docker-compose.yml - do not change this\n",
    "dialect = 'postgresql'  # Could be almost any other DB technology\n",
    "host = 'postgresql'  # Name of the Kubernetes service\n",
    "port = 5432\n",
    "\n",
    "# URL-encode password for characters like %, ä, ...\n",
    "password = parse.quote_plus(password)\n",
    "\n",
    "url = f'{dialect}://{username}:{password}@{host}:{port}/{database}'\n",
    "engine = create_engine(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of your database - this database does NOT exist yet (create it below with `create_database()`)\n",
    "database = 'my-new-database'\n",
    "\n",
    "# Connection details according to docker-compose.yml - do not change this\n",
    "dialect = 'mysql+mysqlconnector'  # Could be almost any other DB technology\n",
    "host = 'mysql'\n",
    "port = 3306\n",
    "username = 'root'\n",
    "password = 'password'\n",
    "# URL-encode password for characters like %, ä, ...\n",
    "password = parse.quote_plus(password)\n",
    "\n",
    "url = f'{dialect}://{username}:{password}@{host}:{port}/{database}'\n",
    "engine = create_engine(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Create a new database once (you start with an empty database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new database called `my-new-database` (or anything, really). This command should return the value `True`, which means you could also successfully connect to the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "\n",
    "print(f'Database \"{database}\" exists: {database_exists(engine.url)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load example data into the database\n",
    "### Postgres\n",
    "Download `northwind.sql` from [this link](https://github.com/pthom/northwind_psql/raw/master/northwind.sql) (shift-click, then `Save link as...`), taken from the famous [Northwind example database](https://github.com/pthom/northwind_psql). Move the file into your `work` directory mounted in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = open(\"/home/jovyan/work/northwind.sql\").read()\n",
    "with engine.begin() as connection:\n",
    "    connection.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MySQL\n",
    "MySQL needs more work. Download the database schema `northwind.sql` and the actual data `northwind-data.sql` from [this Github Repo](https://github.com/dalers/mywind). Move the 2 files into your `work` directory mounted in Jupyter.\n",
    "\n",
    "Read the SQL commands in sequence and feed the individual commands (separated by a `;` and a subsequent line-break) individually to MySQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in (\"/home/jovyan/work/northwind.sql\", \"/home/jovyan/work/northwind-data.sql\"):\n",
    "    sql = open(filename).read()\n",
    "    with engine.begin() as connection:\n",
    "        for command in sql.split(';\\n'):\n",
    "            if not command.strip() or command.startswith('--'):\n",
    "                # Empty or commented line - MySQL would throw an exception\n",
    "                continue\n",
    "            connection.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Explore the DB\n",
    "Apart from the database itself and the table, you might need to specify a schema. In our case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres - let's use the standard/default schema\n",
    "schema = 'public'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL - the load above created its own schema\n",
    "schema = 'northwind'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all tables in the current database. SQLAlchemy uses an object called `MetaData` to describe the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the metadata with our database (the engine-object)\n",
    "meta = MetaData(bind=engine, schema=schema)\n",
    "# Load the existing database metadata from the database into meta\n",
    "meta.reflect()\n",
    "# Print all tables\n",
    "meta.tables.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all columns of all tables of the current database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in meta.sorted_tables:\n",
    "    for column in table.columns:\n",
    "        print(f'{table.name}: {column.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLAlchemy and Pandas Dataframes\n",
    "SQLAlchemy plays nicely with Pandas. In general, you pass the `Engine`-object to Pandas as well as the schema - that's it.\n",
    "\n",
    "To get you started, try this to **read** an entire DB table into a dataframe `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'customers'\n",
    "df = pd.read_sql_table(\n",
    "    table_name,\n",
    "    con=engine,\n",
    "    schema=schema,\n",
    "    index_col='customer_id'  # column name to use as dataframe-index (optional)\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **write** a dataframe `df` to a new table, do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'customers_copy'\n",
    "\n",
    "df.to_sql(\n",
    "    table_name,\n",
    "    con=engine,\n",
    "    schema=schema,\n",
    "    if_exists='fail',  # What to do with an existing table? Could also be `replace` or `append`\n",
    "    index=True,  # Whether to write the dataframe index as an additional column. Won't be a primary key automatically!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an entity diagram to understand the structure of the database\n",
    "[SQLAlchemy_Schemadisplay](https://github.com/sqlalchemy/sqlalchemy/wiki/SchemaDisplay) allows you to quickly see the structure of a DB like this: ![example schema](https://raw.githubusercontent.com/wiki/sqlalchemy/sqlalchemy/UsageRecipes/SchemaDisplay/schema.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy_schemadisplay import create_schema_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Postgres only:** We need to do some cleanup as SQLAlchemy did not recognize all DB types: `SAWarning: Did not recognize type 'bpchar' of column 'customer_id'`. Every column needs to have set a type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postgres only\n",
    "# SQLAlchemy has issues with the following columns when using Postgres. They all seem to be strings\n",
    "offending = ['territory_description', 'region_description', 'customer_id', 'customer_type_id']\n",
    "\n",
    "from sqlalchemy.types import VARCHAR\n",
    "\n",
    "for table in meta.sorted_tables:\n",
    "    for column in table.columns:\n",
    "        if column.name in offending:\n",
    "            print(f'{table.name}: {column.name}')\n",
    "            column.type = VARCHAR(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the entity diagram. It will be saved as `db_entity_diagram.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_schema_graph(metadata=meta,\n",
    "   show_datatypes=True,\n",
    "   show_indexes=True,\n",
    "   rankdir='LR', # From left to right (instead of top to bottom)\n",
    "   concentrate=False # Don't try to join the relation lines together\n",
    ")\n",
    "\n",
    "graph.write_png('db_entity_diagram.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
